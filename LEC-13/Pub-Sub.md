## Pub-Sub

Wormhole: Reliable Pub-Sub to support Geo-replicated Internet Services.

Wormhole：可靠的Pub-Sub支持全球复制的互联网服务。

为什么我们读这篇文章？

* 分布式系统中的pub-sub公共构建块
    YMB，FAB，Kafka
* 案例研究：Facebook的Wormhole
    由memcache驱动

网站如何扩大负载增长？一个典型的演变历史：

* 一台机器，Web服务器，应用程序，DB
     数据库存储在磁盘，崩溃恢复，事务，SQL
     应用查询DB，格式，HTML和c
     但负载增长，您的PHP应用程序花费太多的CPU时间
* 许多Web FE，一个共享数据库
     一个容易的变化，因为Web服务器+应用程序已经与存储分离
     FE是无状态的，通过DB共享（并发控制）
     但负荷增长; 添加更多FE; 很快单个DB服务器就是瓶颈
* 许多Web FE，数据分组在数据库集群上
     通过数据块的键分割数据
       应用程序查看关键字（例如用户），选择正确的数据库
     如果没有数据是超级流行的，很好的数据库并行性
     痛苦的交叉分页交易和查询可能不起作用
       难以划分太细
     但是DB很慢，即使是读，为什么不缓存读请求？
* 许多Web FE，许多用于读取的缓存，许多用于写入的DB
     经济实惠的b / c读取和memcached比DB快10倍
       memcached只是一个内存中的哈希表，很简单
     复杂的b / c DB和memcached可能会失去同步
     （下一个瓶颈将是DB写 - 很难解决）

大Facebook的基础设施图片

很多用户，朋友列表，状态，帖子，喜欢，照片，新鲜/一致的数据显然不是关键

* 高负载：每秒数十亿次操作，这是一个DB服务器的吞吐量的10,000倍
* 多个数据中心（至少西海岸和东海岸）每个数据中心 - “区域”：“真实”数据通过MySQL数据库分片，memcached层（mc），web服务器（memcached的客户端），每个数据中心的数据库都包含完整的副本，西海岸是Master，其他人是通过MySQL异步日志复制的replication

FB在mc中存储什么？

也许userID  - > name; userID  - >朋友列表; postID  - > text; 网址 - >喜欢;基本上从DB复制数据

FB应用程序如何使用mc？
```

	读：
    v = get（k）（计算哈希（k）以选择mc服务器）
    如果v为零{
      v =从本地DB获取
      set（k，v）
    }
    写：
    v =新值
    发送k，v到主DB＃可能在偏远地区

```

如何安排不同地区的数据库更新？
  主数据库接收所有写入（类似于PNUTS）
  将条目添加到事务日志
  将事务日志复制到从站

如何安排mc在不同地区了解写作

* 需要在写入后无效/更新mc条目
    eval部分建议避免过时的数据很重要
* 选项1：远程区域的mc轮询其本地DB
     增加DB上的读取负载
     什么是轮询间隔？
* 选项2：虫洞酒吧/子

发布/订阅
  分布式系统中的共同构建块
  Facebook用例
    用户是mc
    发布商是DB
  订阅者链接我们的图书馆
    更新配置文件以表示对更新的兴趣
    储存在动物园管理员
  发布商阅读配置文件以查找订阅者
    与每个用户建立流
    每个流异步地发送蠕虫孔更新
      一组键值对
  过滤器
    订阅者告诉发布商有关过滤器
    过滤器是在蠕虫孔更新中的密钥查询
    发布商只发送通过过滤器的更新

传递语义
  流量上的所有更新按顺序交付
  发布者维护每个用户一个“数据标记”
    事务日志中更新的序列号
    记录订阅者收到的内容
  发布商定期询问订阅者收到的内容
    即，标记是用户已经收到的下限
  更新至少交付一次
    发布商持续标记
    如果发布商无法从上一个标记开始发送
    =>订阅者可能会收到两次更新
  问：订户如何处理多次提供的更新
    A：缓存没问题
    答：应用程序可以进行重复过滤
  问：是不是可以更新？
    答：是的，因为事务日志可能已被截断
       日志中的数据存在1-2天
       
问：用户为什么不跟踪标记？
   A：FB希望用户无国籍

问：为什么标签定期由订阅者确认
   A：昂贵的每一次更新
   A：使用TCP进行交付
     他们不必担心丢包

在哪里存放标记？
  SCRD：发布商存储在本地持久存储中
    如果存储不可用，则无法将故障切换到新的发布者
       缓存将会过时
    如果存储失败，丢失标记
    机会：存储/日志经常被复制
  MCRD：发行商在Zookeeper中存储标记
    如果发布商失败，另一个发布商可以接管
    从zookeeper读取最后一个标记
    实施挑战：标记格式
      相同日志的副本具有不同的二进制格式
      解决方案：“逻辑”的立场
  问：在Zookeeper中更新标记不是很贵吗？
    答：是的，但只定期进行

实施挑战：许多不同的DB
  不想修改任何一个来支持流
  想法：发布商读取DB的事务日志
    读库读取不同的日志格式
    以标准格式转换更新（蠕虫更新）
    一个键是分片标识符

优化1：大篷车
  设计1：每流一个读者
    对DB负载过大
    在稳定状态下，所有读者都读取相同的更新
  设计2：一个读者为所有流
    恢复性能不佳
    在恢复每个流程可能必须从日志中的不同点读取
  解决方案：每个流的一个读者（“大篷车”）
    在实践中，大篷车的数量很少（〜1）
    一个大篷车叫做“大篷车”
    
优化2：负载平衡流
  单个应用程序有几个订阅者
    应用程序数据也被分解
    N DB分片
    M应用机
    - > MC机器可能有多于1个用户
       例如，当它存储2个DB分片时
    问：创建一个新流程应用程序机器是用户？ 
  两个计划：
    - 加权随机选择
    - 订阅者使用zookeeper

优化3：一个TCP连接
  为同一用户复用多个流
  用户可能有几个分片
  每个分片的一个流程

部署
  在FB使用
  几个DB的读者（MySQL，HDFS，...）
  每天更新35 GB
  ＃caravans = 1.06    

性能
  服务瓶颈：350 Mbyte / s
  用户瓶颈：60万次更新/ s

参考
  Kafka（http://research.microsoft.com/en-us/um/people/srikanth/netdb11/netdb11papers/netdb11-final12.pdf）
